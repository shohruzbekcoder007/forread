# ds.py

import torch
import deepspeed
from transformers import AutoTokenizer, AutoModelForCausalLM

# ðŸš€ 1. Model nomi
model_name = "meta-llama/Llama-2-7b"

# ðŸš€ 2. Tokenizer yuklash (SentencePiece uchun use_fast=False)
tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)

# ðŸš€ 3. Model yuklash
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.float16,  # GPU uchun optimallashtirish
    device_map="auto"           # DeepSpeed bilan GPU mapping
)

# ðŸš€ 4. DeepSpeed konfiguratsiya (oddiy)
ds_engine = deepspeed.initialize(model=model)[0]

# ðŸš€ 5. Sinov uchun oddiy input
inputs = tokenizer("Assalomu alaykum, dunyo!", return_tensors="pt").to(ds_engine.device)

# ðŸš€ 6. Forward pass
with torch.no_grad():
    outputs = ds_engine.generate(**inputs, max_new_tokens=20)

# ðŸš€ 7. Natija
print(tokenizer.decode(outputs[0], skip_special_tokens=True))
