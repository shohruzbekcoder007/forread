import torch
from transformers import AutoModelForCausalLM, AutoTokenizer

model_name = "unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit"

# Tokenizer va modelni yuklash
tokenizer = AutoTokenizer.from_pretrained(model_name)

# Modelni yuklash (bnb-4bit quantized model uchun device_map="auto")
model = AutoModelForCausalLM.from_pretrained(model_name, device_map="auto")

# Matnni tokenizatsiya qilish
inputs = tokenizer("Assalomu alaykum, bugun ob-havo", return_tensors="pt").to("cuda")

# Model orqali generatsiya qilish
outputs = model.generate(**inputs, max_new_tokens=50)

# Natijani chiqarish
print(tokenizer.decode(outputs[0], skip_special_tokens=True))
